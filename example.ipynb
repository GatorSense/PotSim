{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d607d44-b7a6-4302-b73c-e9cfcaf6b1d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T22:21:56.290663Z",
     "iopub.status.busy": "2025-01-31T22:21:56.290540Z",
     "iopub.status.idle": "2025-01-31T22:22:27.694105Z",
     "shell.execute_reply": "2025-01-31T22:22:27.693609Z",
     "shell.execute_reply.started": "2025-01-31T22:21:56.290647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.multiprocessing as mp\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "from utils import preprocessing as ppsr\n",
    "from utils.potsimloader import potsimloader as psl\n",
    "from utils import split\n",
    "from models import linearregression, mlp, cnn, tcn, lstm, transformer\n",
    "from utils import scaler\n",
    "from training import train\n",
    "from testing import evaluate\n",
    "pl.enable_string_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43322abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d639d061-7d7f-4ddd-af0d-2215594f45a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T22:22:27.696338Z",
     "iopub.status.busy": "2025-01-31T22:22:27.696065Z",
     "iopub.status.idle": "2025-01-31T22:22:27.700280Z",
     "shell.execute_reply": "2025-01-31T22:22:27.699914Z",
     "shell.execute_reply.started": "2025-01-31T22:22:27.696322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_FEATURES = {\n",
    "    \"NTotL1\": [\"DayAfterPlant\", \"NApp\", \"Rain\", \"SolarRad\", \"AirTempC\"],\n",
    "    \"NTotL2\": [\"DayAfterPlant\", \"NApp\", \"Rain\", \"SolarRad\", \"AirTempC\"],\n",
    "    \"SWatL1\": ['DayAfterPlant','IrrgThresh', 'NLeach', 'Irrg', 'Rain'],\n",
    "    \"SWatL2\": ['DayAfterPlant','IrrgThresh', 'NLeach', 'Irrg', 'Rain'],\n",
    "    \"NLeach\": ['NTotL1', 'NTotL2', 'Rain', 'SolarRad', 'AirTempC'],\n",
    "    \"NPlantUp\": ['DayAfterPlant', 'NTotL1', 'NTotL2', 'Rain', 'SolarRad', 'AirTempC']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06214f0e-d709-4086-9360-7d84bc8c401b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T22:22:27.706446Z",
     "iopub.status.busy": "2025-01-31T22:22:27.706328Z",
     "iopub.status.idle": "2025-01-31T22:22:27.717604Z",
     "shell.execute_reply": "2025-01-31T22:22:27.717215Z",
     "shell.execute_reply.started": "2025-01-31T22:22:27.706433Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)  # Set seed for PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # Set seed for PyTorch GPU (if using CUDA)\n",
    "    np.random.seed(seed)  # Set seed for NumPy\n",
    "    random.seed(seed)  # Set seed for Python's random module\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c6d50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_treatments(n_values):\n",
    "    combis = list(itertools.product(n_values, repeat=3))\n",
    "    return [\"-\".join(map(str, t)) for t in combis if sum(t) <= 400]\n",
    "\n",
    "\n",
    "def join_potsim_yearly(data_dir, save_dir=Path(\"data\")):\n",
    "    data_dir = Path(data_dir).resolve()\n",
    "    files = os.listdir(data_dir)\n",
    "    pattern = re.compile(r\"^potsim_\\d{4}\\.parquet$\")\n",
    "    files = sorted([file for file in files if pattern.match(file)])\n",
    "    files = [data_dir / file for file in files]\n",
    "    df = pl.scan_parquet(files)\n",
    "    filepath = save_dir / \"potsim.parquet\"\n",
    "    df.sink_parquet(\n",
    "        filepath,\n",
    "        statistics=True,\n",
    "        compression=\"zstd\",\n",
    "        compression_level=1,\n",
    "        row_group_size=1_000_000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = ['Year', 'Date', 'Treatment', 'NFirstApp','PlantingDay', 'IrrgDep',\n",
    "           'IrrgThresh', 'DayAfterPlant', 'NApp', 'NLeach', 'NPlantUp', 'NTotL1', \n",
    "           'NTotL2', 'Irrg', 'SWatL1', 'SWatL2', 'Rain', 'SolarRad', 'AirTempC']\n",
    "   \n",
    "mask = (\n",
    "    ((pl.col(\"NFirstApp\") == \"Npl\") & (pl.col(\"DayAfterPlant\") >= -1)) |\n",
    "    ((pl.col(\"NFirstApp\") == \"Npre\") & (pl.col(\"DayAfterPlant\") >= -37))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b958fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "potsim_dir = \"data/potsim_yearly/\"\n",
    "weather_file = \"data/weather.parquet\"\n",
    "join_potsim_yearly(potsim_dir)\n",
    "data_file = \"data/potsim.parquet\"\n",
    "\n",
    "data = psl.read_data(\n",
    "    dataset_path=data_file,\n",
    "    weather_path=weather_file,\n",
    "    usecols=usecols,\n",
    "    lazy=True,\n",
    "    as_pandas=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea712ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [0, 56, 112, 168, 196]\n",
    "treatments = generate_treatments(n_values)\n",
    "scenario_filter= {\n",
    "    \"Year\": list(range(2001, 2025)),\n",
    "    \"Treatment\": treatments,\n",
    "    \"PlantingDay\": [1, 15, 29, 43, 57],\n",
    "    \"IrrgDep\": [30, 40, 50, 60],\n",
    "    \"IrrgThresh\": [50, 60, 70, 80, 90],\n",
    "    \"NFirstApp\": [\"Npl\", \"Npre\"]\n",
    "}\n",
    "train_years = list(range(2001, 2017))\n",
    "val_years = list(range(2017, 2021))\n",
    "test_years = list(range(2021, 2025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf679bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = psl.apply_filter(data, filters=scenario_filter, lazy=False, as_pandas=True)\n",
    "df = data.filter(mask).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fcc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenarios: train(13392), val(4464), test(4464)\n"
     ]
    }
   ],
   "source": [
    "train_split, val_split, test_split = split.random_sample_train_val_test(\n",
    "    df,\n",
    "    split=(0.6, 0.2, 0.2),\n",
    "    train_years=[2001, 2002, 2023],\n",
    "    val_years=[2002],\n",
    "    test_years=[2002],\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b84b0efd-91be-4bf8-85c9-21ca9c17b8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T22:23:19.641264Z",
     "iopub.status.busy": "2025-01-31T22:23:19.640990Z",
     "iopub.status.idle": "2025-01-31T22:23:19.918391Z",
     "shell.execute_reply": "2025-01-31T22:23:19.917914Z",
     "shell.execute_reply.started": "2025-01-31T22:23:19.641247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_col = \"NTotL1\"\n",
    "feature_cols = TARGET_FEATURES[target_col]\n",
    "output_dir = Path() / \"outputs\" / target_col\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "scaler_save_path =  output_dir / f\"{target_col}_scaler.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b771ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Non-Sequential models like LinearRegression, MLP etc.\n",
    "seq_len = None\n",
    "# For Sequential models like CNN, TCN, LSTM etc.\n",
    "# seq_len = 15\n",
    "\n",
    "X_train, y_train = ppsr.process_data(\n",
    "    train_split,\n",
    "    feats=feature_cols,\n",
    "    tgt=target_col,\n",
    "    scaler_path=scaler_save_path,\n",
    "    mode=\"fit\",\n",
    "    seq_len=seq_len,\n",
    ")\n",
    "X_val, y_val = ppsr.process_data(\n",
    "    val_split,\n",
    "    feats=feature_cols,\n",
    "    tgt=target_col,\n",
    "    scaler_path=scaler_save_path,\n",
    "    mode=\"transform\",\n",
    "    seq_len=seq_len,\n",
    ")\n",
    "X_test, y_test = ppsr.process_data(\n",
    "    test_split,\n",
    "    feats=feature_cols,\n",
    "    tgt=target_col,\n",
    "    scaler_path=scaler_save_path,\n",
    "    mode=\"transform\",\n",
    "    seq_len=seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train shapes: \\nX_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Val shapes: \\nX_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"Test shapes: \\nX_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LinearRegression\"\n",
    "model = linearregression.LinearRegression(input_dim=5)\n",
    "model_state = output_dir / f\"{target_col}_LinearRegression.pth\"\n",
    "\n",
    "# model_name = \"MLP\"\n",
    "# model = mlp.MLP(input_dim=5, hidden_size=128, num_layers=2, dropout=0.2)\n",
    "# model_state = output_dir / f\"{target_col}_MLP.pth\"\n",
    "\n",
    "# model_name = \"CNN1D\"\n",
    "# model = cnn.CNN1D(input_dim=5, hidden_size=64, kernel_size=3, padding=1, dropout=0.2)\n",
    "# model_state = output_dir / f\"{target_col}_CNN1D.pth\"\n",
    "\n",
    "# model_name = \"TCN\"\n",
    "# model = tcn.TCN(input_dim=5, num_channels=[64,32,16,8], kernel_size=3, dropout=0.2)\n",
    "# model_state = output_dir / f\"{target_col}_TCN.pth\"\n",
    "\n",
    "# model_name = \"LSTM\"\n",
    "# model = lstm.LSTM(input_dim=5, hidden_size=64, num_layers=2, dropout=0.2)\n",
    "# model_state = output_dir / f\"{target_col}_LSTM.pth\"\n",
    "\n",
    "# model_name = \"EncoderOnlyTransformer\"\n",
    "# model = transformer.EncoderOnlyTransformer(\n",
    "#     input_dim=5, nhead=2, num_layers=2, d_model=64, dropout=0.2, max_seq_len=15\n",
    "# )\n",
    "# model_state = output_dir / f\"{target_col}_EncoderOnlyTransformer.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting model to device\n",
    "model.to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for calculating and printing metrics during training\n",
    "min_tgt, max_tgt = scaler.get_min_max(tgt=target_col, scaler_path=scaler_save_path)\n",
    "min_tgt = torch.tensor(min_tgt, device=device)\n",
    "max_tgt = torch.tensor(max_tgt, device=device)\n",
    "print(min_tgt, max_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c59af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "b_sz = 256\n",
    "max_epochs = 10\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-8\n",
    ")\n",
    "epochs_no_improve = 0\n",
    "min_loss_reduction=1e-4\n",
    "early_stop_patience: int = 10\n",
    "ampscaler = torch.amp.GradScaler(device=device.type)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_save_path = output_dir / f\"{target_col}_{model_name}.pth\"\n",
    "logs_save_path = output_dir / f\"logs_{target_col}_{model_name}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97893392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataloader\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train),\n",
    "    num_workers=10,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, y_val),\n",
    "    num_workers=4,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    batch_size=b_sz,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa398a8-d1fb-49f2-86a2-0b0b3f6cc576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T08:07:11.944087Z",
     "iopub.status.busy": "2025-01-31T08:07:11.943766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP on device: cuda\n",
      "Epoch: 0/9 | Train Loss: 0.01124, Train R²: 0.7503 | Val Loss: 0.00736, Val R²: 0.8410 | LR: 0.005, Time: 39.36 secs\n",
      "Epoch: 1/9 | Train Loss: 0.00877, Train R²: 0.8051 | Val Loss: 0.00716, Val R²: 0.8452 | LR: 0.005, Time: 38.75 secs\n",
      "Epoch: 2/9 | Train Loss: 0.00838, Train R²: 0.8139 | Val Loss: 0.00687, Val R²: 0.8516 | LR: 0.005, Time: 38.93 secs\n",
      "Epoch: 3/9 | Train Loss: 0.00814, Train R²: 0.8193 | Val Loss: 0.00685, Val R²: 0.8520 | LR: 0.005, Time: 41.64 secs\n",
      "Epoch: 4/9 | Train Loss: 0.00794, Train R²: 0.8237 | Val Loss: 0.00669, Val R²: 0.8555 | LR: 0.005, Time: 43.22 secs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training {model_name }on device: {device}\")\n",
    "# Training Loop\n",
    "best_val_loss = float(\"inf\")\n",
    "train_val_logs = []\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # Break loop if early stop triggered\n",
    "    if early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_r2 = train.train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        min_tgt,\n",
    "        max_tgt,\n",
    "        ampscaler=ampscaler,\n",
    "    )\n",
    "    val_loss, val_r2 = train.val_epoch(model, val_loader, criterion, device, min_tgt, max_tgt)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stop and save logic\n",
    "    if val_loss < best_val_loss - min_loss_reduction:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve > early_stop_patience:\n",
    "            early_stop = True\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    train_val_logs.append(\n",
    "        {\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_r2\": train_r2,\n",
    "            \"val_r2\": val_r2,\n",
    "            \"learning_rate\": curr_lr,\n",
    "        }\n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1}/{max_epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.5f}, Train R²: {train_r2:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.5f}, Val R²: {val_r2:.4f} | \"\n",
    "        f\"LR: {curr_lr}, Time: {round(elapsed, 2)} secs\"\n",
    "    )\n",
    "if not model_save_path.exists():\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "train_val_df = pd.DataFrame(train_val_logs)\n",
    "train_val_df.to_csv(logs_save_path, index=False)\n",
    "print(\"Training Complete....!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ef42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = pd.read_csv(logs_save_path)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x=\"epoch\", y=\"train_loss\", data=df_log, label=\"Train Loss\")\n",
    "sns.lineplot(x=\"epoch\", y=\"val_loss\", data=df_log, linestyle=\"--\", label=\"Val Loss\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig(output_dir / f\"{target_col}_losscurve.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4635212",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test, y_test),\n",
    "    num_workers=4,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    batch_size=b_sz,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef04080",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, rmse, nrmse, r2 = evaluate.evaluate_model(\n",
    "    model,\n",
    "    data_loader=test_loader,\n",
    "    tgt=target_col,\n",
    "    device=device,\n",
    "    scaler_path=scaler_save_path,\n",
    ")\n",
    "print(f\"\\n\\nMean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Square Error: {rmse:.4f}\")\n",
    "print(f\"Normalized Root Mean Square Error: {nrmse:.4f}\")\n",
    "print(f\"Coefficient of determination (R-Squared): {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e31cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potsim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
